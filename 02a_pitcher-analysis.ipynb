{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting Baseball Hall of Fame Induction\n",
    "\n",
    "###  Analysis 1 of 4 -- Pitchers\n",
    "\n",
    "####  Eryk Wdowiak and Ken Hoffman\n",
    "\n",
    "data from Lahman Baseball Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import VotingClassifier ##, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  the little date string\n",
    "dt_str = '2020-08-19a'\n",
    "\n",
    "##  pick a dataframe from pickle files\n",
    "pitchers_df = pickle.load(open('pitchers-df_'+ dt_str +'.p','rb'))\n",
    "# catchers_df = pickle.load(open('catchers-df_'+ dt_str +'.p','rb'))\n",
    "# infielders_df = pickle.load(open('infielders-df_'+ dt_str +'.p','rb'))\n",
    "# outfielders_df = pickle.load(open('outfielders-df_'+ dt_str +'.p','rb'))\n",
    "\n",
    "##  give that dataframe an alias\n",
    "df = pitchers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bball_log(x):\n",
    "    warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "    return np.where(x<1,0,np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(x, prefix):\n",
    "    return pd.get_dummies(x, prefix = prefix, drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  list to take logs of\n",
    "log_list = ['G','G_ps','W','W_ps','SO','SO_ps',\n",
    "            'ER','ER_ps','IPouts','IPouts_ps','nu_sns']\n",
    "\n",
    "##  take logs\n",
    "for vbl in log_list:\n",
    "    new = 'ln_'+vbl\n",
    "    df[new] = bball_log(df[vbl])\n",
    "\n",
    "##  years since retirement\n",
    "df['since_lst'] = 2018 - df['lst_sn']\n",
    "df['ln_since'] = np.log(df['since_lst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  I do NOT think it's a good idea to use team dummies.\n",
    "##  The estimated regression coefficients for a team with one (or few) \n",
    "##  inductees could be large, while the true values are zero.\n",
    "##  \n",
    "##  Nonetheless, to include team dummies, you would add the line:\n",
    "##  ##  exog = exog + tm_incl\n",
    "##  to the model formulation below.\n",
    "\n",
    "##  create dummies for teams\n",
    "team_dums = dummies(df['teamID'],'tm')\n",
    "# df = df.join(team_dums)\n",
    "\n",
    "##  just need the list\n",
    "team_cols = team_dums.columns\n",
    "\n",
    "##  exclude teams without pitcher inductees\n",
    "tm_excl = ['tm_ANA', 'tm_ARI', 'tm_BRO', 'tm_BSN', 'tm_CIN', 'tm_COL', \n",
    "           'tm_FLO', 'tm_HOU', 'tm_KC1', 'tm_KCA', 'tm_LAA', 'tm_MIL', \n",
    "           'tm_ML4', 'tm_MON', 'tm_NY1', 'tm_PHA', 'tm_PIT', 'tm_SLA', \n",
    "           'tm_TBA', 'tm_TEX', 'tm_TOR', 'tm_WAS', 'tm_WS1', 'tm_WS2']\n",
    "\n",
    "##  make everything relative to the New York Yankees\n",
    "tm_excl = tm_excl + ['tm_NYA']\n",
    "\n",
    "##  columns to include\n",
    "tm_incl = [dum for dum in team_cols if dum not in tm_excl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  prepare training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  when splitting, how many in test?\n",
    "tts_test_size = 400\n",
    "\n",
    "##  what should be SMOTE's ratio of minority to majority?\n",
    "smote_ratio = 0.125\n",
    "\n",
    "##  random states\n",
    "tts_randm = 19\n",
    "smote_randm = 42\n",
    "\n",
    "##  train_test_split()\n",
    "XX = df.drop(columns=['induct'])\n",
    "yy = df['induct']\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, \n",
    "                                                    random_state = tts_randm,\n",
    "                                                    test_size = tts_test_size)\n",
    "\n",
    "##  Fit SMOTE to training data\n",
    "Xs_train = X_train.drop(columns=['playerID','teamID'])\n",
    "Xs_test  = X_test.drop(columns=['playerID','teamID'])\n",
    "X_smote, y_smote = SMOTE(sampling_strategy = smote_ratio,\n",
    "                         random_state = smote_randm).fit_sample(Xs_train, y_train)\n",
    "\n",
    "##  recreate the old layout\n",
    "df_train = X_train.join(y_train)\n",
    "df_test = X_test.join(y_test)\n",
    "df_smote = X_smote.join(y_smote)\n",
    "\n",
    "##  clean up!\n",
    "del XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  estimation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  keep a list of models\n",
    "# models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logit results below on fit to WHOLE dataset\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049565\n",
      "         Iterations 11\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 induct   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      893\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 20 Aug 2020   Pseudo R-squ.:                  0.7109\n",
      "Time:                        12:07:43   Log-Likelihood:                -44.609\n",
      "converged:                       True   LL-Null:                       -154.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.390e-44\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -60.0081     18.796     -3.193      0.001     -96.847     -23.169\n",
      "ln_G           3.5331      1.063      3.323      0.001       1.449       5.617\n",
      "ln_W          11.2482      3.999      2.813      0.005       3.411      19.086\n",
      "ln_SO          3.1603      1.517      2.083      0.037       0.187       6.133\n",
      "ln_ER        -13.4073      3.634     -3.689      0.000     -20.530      -6.284\n",
      "ln_IPouts      4.5674      6.054      0.754      0.451      -7.298      16.433\n",
      "ln_since       1.6173      0.621      2.605      0.009       0.400       2.834\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.58 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "F1 on train data: 82.61\n",
      "F1 on test data:  73.33\n"
     ]
    }
   ],
   "source": [
    "##  list of exogenous variables for regression model\n",
    "exog = ['ln_G']\n",
    "# exog = exog + ['ln_G_ps']\n",
    "exog = exog + ['ln_W']\n",
    "# exog = exog + ['ln_W_ps']\n",
    "exog = exog + ['ln_SO']\n",
    "# exog = exog + ['ln_SO_ps']\n",
    "exog = exog + ['ln_ER']\n",
    "# exog = exog + ['ln_ER_ps']\n",
    "exog = exog + ['ln_IPouts']\n",
    "# exog = exog + ['ln_IPouts_ps']\n",
    "# exog = exog + ['ln_nu_sns']\n",
    "exog = exog + ['ln_since']\n",
    "\n",
    "##  regression formula\n",
    "m01a_fmla = 'induct~'\n",
    "m01a_fmla = m01a_fmla + '+'.join(exog)\n",
    "\n",
    "##  run logit\n",
    "print()\n",
    "print('logit results below on fit to WHOLE dataset')\n",
    "print()\n",
    "m01a_lgt = smf.logit(m01a_fmla,data=df).fit()\n",
    "print(m01a_lgt.summary())\n",
    "\n",
    "## instantiate standard logit model\n",
    "logit_mdl = LogisticRegression(penalty='none',max_iter=500) \n",
    "\n",
    "##  add to list of models\n",
    "# models['logit_mdl'] = logit_mdl\n",
    "\n",
    "## fit the model\n",
    "#logit_mdl.fit(X_train[exog], y_train)\n",
    "logit_mdl.fit(X_smote[exog], y_smote)\n",
    "\n",
    "## generate predictions\n",
    "y_hat_train = logit_mdl.predict(X_train[exog])\n",
    "y_hat_pred  = logit_mdl.predict(X_test[exog])\n",
    "\n",
    "## calculate F1 scores\n",
    "fone_train = f1_score(y_train,y_hat_train) * 100\n",
    "fone_test  = f1_score(y_test, y_hat_pred)  * 100\n",
    "print()\n",
    "print('F1 on train data: {:.2f}'.format(fone_train))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test))\n",
    "\n",
    "## calculate F1 scores\n",
    "acc_train = accuracy_score(y_train,y_hat_train) * 100\n",
    "acc_test  = accuracy_score(y_test, y_hat_pred)  * 100\n",
    "# print()\n",
    "# print('Acc on train data: {:.2f}'.format(acc_train))\n",
    "# print('Acc on test data:  {:.2f}'.format(acc_test))\n",
    "\n",
    "## clean up\n",
    "del y_hat_train, y_hat_pred, fone_train, fone_test, acc_train, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features\n",
    "\n",
    "\n",
    "X = df[['ln_W', 'ln_G', 'ln_IPouts', 'ln_SO', 'ln_ER', 'ln_since']]\n",
    "\n",
    "# Create target variable\n",
    "y = df['induct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_G</th>\n",
       "      <th>ln_W</th>\n",
       "      <th>ln_SO</th>\n",
       "      <th>ln_ER</th>\n",
       "      <th>ln_IPouts</th>\n",
       "      <th>ln_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>6.725034</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>6.445720</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>7.867871</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>6.322565</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>6.364751</td>\n",
       "      <td>5.771441</td>\n",
       "      <td>7.620705</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>6.129050</td>\n",
       "      <td>4.672829</td>\n",
       "      <td>6.799056</td>\n",
       "      <td>6.820016</td>\n",
       "      <td>8.658866</td>\n",
       "      <td>4.043051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>5.332719</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>5.945421</td>\n",
       "      <td>5.598422</td>\n",
       "      <td>7.593374</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>6.056784</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>6.230481</td>\n",
       "      <td>5.717028</td>\n",
       "      <td>7.579168</td>\n",
       "      <td>3.178054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ln_G      ln_W     ln_SO     ln_ER  ln_IPouts  ln_since\n",
       "666  6.725034  3.891820  6.445720  5.860786   7.867871  2.564949\n",
       "347  6.322565  3.555348  6.364751  5.771441   7.620705  2.708050\n",
       "784  6.129050  4.672829  6.799056  6.820016   8.658866  4.043051\n",
       "592  5.332719  3.526361  5.945421  5.598422   7.593374  2.890372\n",
       "582  6.056784  3.332205  6.230481  5.717028   7.579168  3.178054"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[exog].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on train data: 80.00\n",
      "F1 on test data:  85.71\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_smote[exog], y_smote)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = clf.predict(X_train[exog]) \n",
    "y_pred_test = clf.predict(X_test[exog]) \n",
    "\n",
    "fone_train_clf = f1_score(y_train, y_pred_train) * 100\n",
    "fone_test_clf = f1_score(y_test, y_pred_test) * 100\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('F1 on train data: {:.2f}'.format(fone_train_clf))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 1, n_estimators=100, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, random_state=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to the training data\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on train data: 76.36\n",
      "F1 on test data:  90.91\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "rfc = rfc.fit(X_smote[exog], y_smote)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = rfc.predict(X_train[exog])\n",
    "y_pred_test = rfc.predict(X_test[exog])\n",
    "\n",
    "fone_train_rfc = f1_score(y_train, y_pred_train) * 100\n",
    "fone_test_rfc = f1_score(y_test, y_pred_test) * 100\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('F1 on train data: {:.2f}'.format(fone_train_rfc))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test_rfc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
