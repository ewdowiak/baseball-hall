{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predicting Baseball Hall of Fame Induction\n",
    "\n",
    "###  Analysis 2 of 4 -- Catchers\n",
    "\n",
    "####  Eryk Wdowiak and Ken Hoffman\n",
    "\n",
    "data from Lahman Baseball Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import VotingClassifier ##, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  the little date string\n",
    "dt_str = '2020-08-19a'\n",
    "\n",
    "##  pick a dataframe from pickle files\n",
    "# pitchers_df = pickle.load(open('pitchers-df_'+ dt_str +'.p','rb'))\n",
    "catchers_df = pickle.load(open('catchers-df_'+ dt_str +'.p','rb'))\n",
    "# infielders_df = pickle.load(open('infielders-df_'+ dt_str +'.p','rb'))\n",
    "# outfielders_df = pickle.load(open('outfielders-df_'+ dt_str +'.p','rb'))\n",
    "\n",
    "##  give that dataframe an alias\n",
    "df = catchers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bball_log(x):\n",
    "    warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "    return np.where(x<1,0,np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(x, prefix):\n",
    "    return pd.get_dummies(x, prefix = prefix, drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  list to take logs of\n",
    "log_list = ['bG','AB','R','H','2B','3B','HR','RBI','bSB','bCS','BB','SO','HBP','SH',\n",
    "            'bG_ps','AB_ps','R_ps','H_ps','2B_ps','3B_ps','HR_ps',\n",
    "            'RBI_ps','bSB_ps','bCS_ps','BB_ps','SO_ps','HBP_ps','SH_ps',\n",
    "            'fG','PO','A','E','DP','fSB','fCS','fG_ps',\n",
    "            'PO_ps','A_ps','E_ps','DP_ps','fSB_ps','fCS_ps','nu_sns']\n",
    "\n",
    "##  take logs\n",
    "for vbl in log_list:\n",
    "    new = 'ln_'+vbl\n",
    "    df[new] = bball_log(df[vbl])\n",
    "\n",
    "##  years since retirement\n",
    "df['since_lst'] = 2018 - df['lst_sn']\n",
    "df['ln_since'] = np.log(df['since_lst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  prepare training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  when splitting, how many in test?\n",
    "tts_test_size = 100\n",
    "\n",
    "##  what should be SMOTE's ratio of minority to majority?\n",
    "smote_ratio = 0.125\n",
    "\n",
    "##  random states\n",
    "tts_randm = 19\n",
    "smote_randm = 42\n",
    "\n",
    "##  train_test_split()\n",
    "XX = df.drop(columns=['induct','position'])\n",
    "yy = df['induct']\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, \n",
    "                                                    random_state = tts_randm,\n",
    "                                                    test_size = tts_test_size)\n",
    "\n",
    "##  Fit SMOTE to training data\n",
    "Xs_train = X_train.drop(columns=['playerID','teamID'])\n",
    "Xs_test  = X_test.drop(columns=['playerID','teamID'])\n",
    "X_smote, y_smote = SMOTE(sampling_strategy = smote_ratio,\n",
    "                         random_state = smote_randm).fit_sample(Xs_train, y_train)\n",
    "\n",
    "##  recreate the old layout\n",
    "df_train = X_train.join(y_train)\n",
    "df_test = X_test.join(y_test)\n",
    "df_smote = X_smote.join(y_smote)\n",
    "\n",
    "##  clean up!\n",
    "del XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  estimation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  keep a list of models\n",
    "# models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logit results below on fit to WHOLE dataset\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.034410\n",
      "         Iterations 13\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 induct   No. Observations:                  237\n",
      "Model:                          Logit   Df Residuals:                      232\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Fri, 21 Aug 2020   Pseudo R-squ.:                  0.8032\n",
      "Time:                        08:37:06   Log-Likelihood:                -8.1553\n",
      "converged:                       True   LL-Null:                       -41.441\n",
      "                                        LLR p-value:                 1.201e-13\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -154.6839     56.435     -2.741      0.006    -265.294     -44.073\n",
      "ln_HR          4.6454      1.823      2.548      0.011       1.072       8.219\n",
      "ln_PO         14.4475      5.543      2.607      0.009       3.584      25.311\n",
      "ln_fCS        -2.0488      0.785     -2.609      0.009      -3.588      -0.510\n",
      "ln_since       2.2124      1.525      1.451      0.147      -0.777       5.201\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.80 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "F1 on train data: 76.92\n",
      "F1 on test data:  88.89\n"
     ]
    }
   ],
   "source": [
    "##  list of exogenous variables for regression model\n",
    "exog = []\n",
    "# exog = exog + ['ln_bG']\n",
    "# exog = exog + ['ln_fG']\n",
    "# exog = exog + ['ln_R']\n",
    "# exog = exog + ['ln_H']\n",
    "# exog = exog + ['ln_2B']\n",
    "# exog = exog + ['ln_3B']\n",
    "exog = exog + ['ln_HR']\n",
    "# exog = exog + ['ln_RBI']\n",
    "# exog = exog + ['ln_bSB']\n",
    "exog = exog + ['ln_PO']\n",
    "# exog = exog + ['ln_A']\n",
    "# exog = exog + ['ln_DP']\n",
    "exog = exog + ['ln_fCS']\n",
    "# exog = exog + ['ln_nu_sns']\n",
    "exog = exog + ['ln_since']\n",
    "\n",
    "##  regression formula\n",
    "m01a_fmla = 'induct~'\n",
    "m01a_fmla = m01a_fmla + '+'.join(exog)\n",
    "\n",
    "##  run logit\n",
    "print()\n",
    "print('logit results below on fit to WHOLE dataset')\n",
    "print()\n",
    "m01a_lgt = smf.logit(m01a_fmla,data=df).fit()\n",
    "print(m01a_lgt.summary())\n",
    "\n",
    "## instantiate standard logit model\n",
    "logit_mdl = LogisticRegression(penalty='none',max_iter=500) \n",
    "\n",
    "##  add to list of models\n",
    "# models['logit_mdl'] = logit_mdl\n",
    "\n",
    "## fit the model\n",
    "#logit_mdl.fit(X_train[exog], y_train)\n",
    "logit_mdl.fit(X_smote[exog], y_smote)\n",
    "\n",
    "## generate predictions\n",
    "y_hat_train = logit_mdl.predict(X_train[exog])\n",
    "y_hat_pred  = logit_mdl.predict(X_test[exog])\n",
    "\n",
    "## calculate F1 scores\n",
    "fone_train = f1_score(y_train,y_hat_train) * 100\n",
    "fone_test  = f1_score(y_test, y_hat_pred)  * 100\n",
    "print()\n",
    "print('F1 on train data: {:.2f}'.format(fone_train))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test))\n",
    "\n",
    "## calculate F1 scores\n",
    "acc_train = accuracy_score(y_train,y_hat_train) * 100\n",
    "acc_test  = accuracy_score(y_test, y_hat_pred)  * 100\n",
    "# print()\n",
    "# print('Acc on train data: {:.2f}'.format(acc_train))\n",
    "# print('Acc on test data:  {:.2f}'.format(acc_test))\n",
    "\n",
    "## clean up\n",
    "del y_hat_train, y_hat_pred, fone_train, fone_test, acc_train, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on train data: 100.00\n",
      "F1 on test data:  72.73\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_smote[exog], y_smote)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = clf.predict(X_train[exog]) \n",
    "y_pred_test = clf.predict(X_test[exog]) \n",
    "\n",
    "fone_train_clf = f1_score(y_train, y_pred_train) * 100\n",
    "fone_test_clf = f1_score(y_test, y_pred_test) * 100\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('F1 on train data: {:.2f}'.format(fone_train_clf))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 1, n_estimators=100, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on train data: 100.00\n",
      "F1 on test data:  72.73\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "rfc = rfc.fit(X_smote[exog], y_smote)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = rfc.predict(X_train[exog])\n",
    "y_pred_test = rfc.predict(X_test[exog])\n",
    "\n",
    "fone_train_rfc = f1_score(y_train, y_pred_train) * 100\n",
    "fone_test_rfc = f1_score(y_test, y_pred_test) * 100\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('F1 on train data: {:.2f}'.format(fone_train_rfc))\n",
    "print('F1 on test data:  {:.2f}'.format(fone_test_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
